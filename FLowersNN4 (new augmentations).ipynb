{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.OutputArea.auto_scroll_threshold = 9999;\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "IPython.OutputArea.auto_scroll_threshold = 9999;\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "IPython.OutputArea.auto_scroll_threshold = 9999;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/student/cb2078/env/lib/python3.10/site-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n",
      "/scratch/student/cb2078/env/lib/python3.10/site-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# get rid of GPU logging messages\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]='3,4,7'\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "import tensorflow_addons as tfa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:2', device_type='GPU')]\n",
      "3 Physical GPUs, 3 Logical GPUs\n",
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:2', device_type='GPU')]\n",
      "3 Physical GPUs, 3 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "# if using a gpu limit its memory usage\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print('e',e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43904\n",
      "43904\n"
     ]
    }
   ],
   "source": [
    "#Load the training and testing dataset\n",
    "#TODO Validation dataset\n",
    "(ds_train, ds_test, ds_val), ds_info = tfds.load('oxford_flowers102',\n",
    "                                            split=['train', 'test', 'validation'],\n",
    "                                            with_info=True,\n",
    "                                            shuffle_files=True,\n",
    "                                            as_supervised=True)\n",
    "\n",
    "#This gets the images ready\n",
    "shape = (800, 800, 3)\n",
    "small_shape = (256, 256, 3)\n",
    "n_labels = 102\n",
    "\n",
    "def normalize_img(img, label):\n",
    "    img = tf.image.resize(img,shape[:2])\n",
    "    img = tf.cast(img, tf.float32) / 255\n",
    "    return (img, label)\n",
    "\n",
    "def resize_img(img, label):\n",
    "    img = tf.image.resize(img,small_shape[:2])\n",
    "    return (img, label)\n",
    "\n",
    "def random_flip_img(img, label):\n",
    "    img = tf.image.random_flip_left_right(img)\n",
    "    return (img, label)\n",
    "\n",
    "def random_crop(img, label):\n",
    "    img = tf.image.resize(img, (int(shape[0] * 1.25), int(shape[1] * 1.25)))\n",
    "    img = tf.image.random_crop(img, shape)\n",
    "    return (img, label)\n",
    "\n",
    "def random_move_img(img, label):\n",
    "    offset = shape[0] / 6\n",
    "    img = tfa.image.translate(\n",
    "        img,\n",
    "        tf.random.uniform(shape = [2], minval = -offset, maxval = offset)\n",
    "    )\n",
    "    return img, label\n",
    "\n",
    "def random_rotate(img, label):\n",
    "    img = tfa.image.rotate(img, tf.random.uniform(shape = [1], minval = -0.5, maxval = 0.5))\n",
    "    return img, label\n",
    "\n",
    "def random_cutout(img, label):\n",
    "    cutout_size = (shape[0] // 64) ** 2\n",
    "    n_cutouts = 10\n",
    "    for _ in range(n_cutouts):\n",
    "        # image.cutout needs a 4d tensor but img is a 3d tensor\n",
    "        img = tfa.image.cutout([img], cutout_size, tf.random.uniform(\n",
    "            shape = [2], maxval = shape[0],\n",
    "            dtype = tf.dtypes.int32\n",
    "        ))\n",
    "        img = img[0,]\n",
    "    return img, label\n",
    "\n",
    "def random_image_warp(img, label):\n",
    "    n_warp_points = 25\n",
    "    offset = shape[0] // 32 \n",
    "    offsets = tf.random.uniform(shape = [n_warp_points, 2], minval = -offset, maxval = offset)\n",
    "    src_points = tf.random.uniform(shape = [n_warp_points, 2], maxval = shape[0])\n",
    "    dest_points = src_points + offsets\n",
    "    img, flow = tfa.image.sparse_image_warp([img], [src_points], [dest_points])\n",
    "    img = img[0,]\n",
    "    return img, label\n",
    "\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "BATCH_SIZE = 64\n",
    "ds_train = ds_train.map(normalize_img, num_parallel_calls=AUTOTUNE)\n",
    "\n",
    "functions = [\n",
    "    random_crop,\n",
    "    random_move_img,\n",
    "    random_rotate,\n",
    "    random_cutout,\n",
    "    random_image_warp,\n",
    "    random_flip_img\n",
    "]\n",
    "repetitions = 7\n",
    "ds_train_orig = ds_train\n",
    "for function in functions:\n",
    "    for _ in range(repetitions):\n",
    "        ds_augmented = ds_train_orig.map(function, num_parallel_calls=AUTOTUNE)\n",
    "        ds_train = ds_train.concatenate(ds_augmented)\n",
    "#     print('-' * 20, function.__name__, '-'*20)\n",
    "#     tfds.visualization.show_examples(ds_augmented, ds_info)\n",
    "ds_train = ds_train.map(resize_img, num_parallel_calls=AUTOTUNE)\n",
    "ds_train = ds_train.cache()\n",
    "ds_train = ds_train.batch(BATCH_SIZE)\n",
    "ds_train = ds_train.prefetch(AUTOTUNE)\n",
    "        \n",
    "ds_test = ds_test.map(normalize_img, num_parallel_calls=AUTOTUNE)\n",
    "ds_test = ds_test.map(resize_img, num_parallel_calls=AUTOTUNE)\n",
    "ds_test = ds_test.batch(BATCH_SIZE)\n",
    "ds_test = ds_test.prefetch(AUTOTUNE)\n",
    "\n",
    "ds_val = ds_val.map(normalize_img, num_parallel_calls=AUTOTUNE)\n",
    "ds_val = ds_val.map(resize_img, num_parallel_calls=AUTOTUNE)\n",
    "ds_val = ds_val.cache()\n",
    "ds_val = ds_val.shuffle(1000)\n",
    "ds_val = ds_val.batch(BATCH_SIZE)\n",
    "ds_val = ds_val.prefetch(AUTOTUNE)\n",
    "\n",
    "print(ds_train.cardinality().numpy() * BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2')\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2')\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 256, 256, 128)     3584      \n",
      " conv2d (Conv2D)             (None, 256, 256, 128)     3584      \n",
      "                                                                 \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 128, 128, 128)    0         \n",
      " max_pooling2d (MaxPooling2D  (None, 128, 128, 128)    0         \n",
      " )                                                               \n",
      " )                                                               \n",
      "                                                                 \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 128, 128, 256)     295168    \n",
      " conv2d_1 (Conv2D)           (None, 128, 128, 256)     295168    \n",
      "                                                                 \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 64, 64, 256)      0         \n",
      " max_pooling2d_1 (MaxPooling  (None, 64, 64, 256)      0         \n",
      " 2D)                                                             \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 64, 64, 256)       0         \n",
      " dropout (Dropout)           (None, 64, 64, 256)       0         \n",
      "                                                                 \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 64, 64, 256)       590080    \n",
      " conv2d_2 (Conv2D)           (None, 64, 64, 256)       590080    \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 32, 32, 256)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 32, 32, 256)       0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 262144)            0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               67109120  \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 32, 32, 256)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 32, 32, 256)       0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 262144)            0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               67109120  \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 102)               26214     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 68,024,166\n",
      "Trainable params: 68,024,166\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      " dense_1 (Dense)             (None, 102)               26214     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 68,024,166\n",
      "Trainable params: 68,024,166\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Making the NN model\n",
    "# model = tf.keras.Sequential([\n",
    "#     tf.keras.layers.Conv2D(32, (3,3), padding='same', activation=\"relu\",input_shape=shape),\n",
    "#     tf.keras.layers.BatchNormalization(),\n",
    "    \n",
    "#     tf.keras.layers.Conv2D(32, (3,3), padding='same', activation=\"relu\"),\n",
    "#     tf.keras.layers.BatchNormalization(),\n",
    "#     tf.keras.layers.MaxPooling2D((2, 2), strides=2),\n",
    "#     tf.keras.layers.Dropout(0.25),\n",
    "\n",
    "#     tf.keras.layers.Conv2D(64, (3,3), padding='same', activation=\"relu\"),\n",
    "#     tf.keras.layers.BatchNormalization(),\n",
    "#     tf.keras.layers.Conv2D(64, (3,3), padding='same', activation=\"relu\"),\n",
    "#     tf.keras.layers.BatchNormalization(),\n",
    "#     tf.keras.layers.Dropout(0.25),\n",
    "\n",
    "#     tf.keras.layers.Flatten(),\n",
    "#     tf.keras.layers.Dense(256, activation=\"relu\"),\n",
    "#     tf.keras.layers.Dense(n_labels, activation=\"softmax\")]\n",
    "# )\n",
    "\n",
    "strategy = tf.distribute.MirroredStrategy()\n",
    "with strategy.scope():   \n",
    "    #Making the NN model\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Conv2D(128, (3,3), padding='same', activation=\"relu\",input_shape=small_shape),\n",
    "        tf.keras.layers.MaxPooling2D((2, 2), strides=2),\n",
    "        #tf.keras.layers.Dropout(0.1),\n",
    "\n",
    "        tf.keras.layers.Conv2D(256, (3,3), padding='same', activation=\"relu\"),\n",
    "        tf.keras.layers.MaxPooling2D((2, 2), strides=2),\n",
    "        tf.keras.layers.Dropout(0.8),\n",
    "\n",
    "        tf.keras.layers.Conv2D(256, (3,3), padding='same', activation=\"relu\"),\n",
    "        tf.keras.layers.MaxPooling2D((2, 2), strides=2),\n",
    "        tf.keras.layers.Dropout(0.8),\n",
    "\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(256, activation=\"relu\"),\n",
    "        tf.keras.layers.Dropout(0.6),\n",
    "        tf.keras.layers.Dense(n_labels, activation=\"softmax\")]\n",
    "    )\n",
    "\n",
    "    #Learning rate scheduler (EXPLAIN THIS)\n",
    "    lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "        initial_learning_rate=0.001,\n",
    "        decay_steps=10000,\n",
    "        decay_rate=0.9\n",
    "    )\n",
    "\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(lr_schedule),\n",
    "        loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n",
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    }
   ],
   "source": [
    "tf.keras.utils.plot_model(\n",
    "    model,\n",
    "    to_file=\"model.png\",\n",
    "    show_shapes=True,\n",
    "    show_layer_names=True,\n",
    "    rankdir=\"TB\",\n",
    "    expand_nested=True,\n",
    "    dpi=96,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/student/cb2078/env/lib/python3.10/site-packages/keras/backend.py:5612: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n",
      "/scratch/student/cb2078/env/lib/python3.10/site-packages/keras/backend.py:5612: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:batch_all_reduce: 10 all-reduces with algorithm = nccl, num_packs = 1\n",
      "INFO:tensorflow:batch_all_reduce: 10 all-reduces with algorithm = nccl, num_packs = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:batch_all_reduce: 10 all-reduces with algorithm = nccl, num_packs = 1\n",
      "INFO:tensorflow:batch_all_reduce: 10 all-reduces with algorithm = nccl, num_packs = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:batch_all_reduce: 10 all-reduces with algorithm = nccl, num_packs = 1\n",
      "INFO:tensorflow:batch_all_reduce: 10 all-reduces with algorithm = nccl, num_packs = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:batch_all_reduce: 10 all-reduces with algorithm = nccl, num_packs = 1\n",
      "INFO:tensorflow:batch_all_reduce: 10 all-reduces with algorithm = nccl, num_packs = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "192/686 [=======>......................] - ETA: 4:19 - loss: 4.7213 - accuracy: 0.0084"
     ]
    }
   ],
   "source": [
    "#Train the model \n",
    "history = model.fit(\n",
    "    ds_train,\n",
    "    epochs=100,\n",
    "    validation_data=ds_val)\n",
    "plt.plot(history.history['accuracy'], label='accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "test_loss, test_acc = model.evaluate(ds_test, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
